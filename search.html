<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Search | Cooper's Cloud</title>
	<meta name="description"
		content="Cooper's Cloud">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- CSS -->
	<link rel="stylesheet" href="/cooperlutz.github.io/assets/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/cooperlutz.github.io/assets/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="/cooperlutz.github.io/search.html">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Cooper's Cloud"
		href="/cooperlutz.github.io/feed.xml" />

	<!-- Font Awesome -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css"
		integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet"
		type="text/css">
	

	<!-- KaTeX -->
	

	<!-- Google Analytics -->
	
</head>
  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/cooperlutz.github.io/">
			<img class="avatar" src="/cooperlutz.github.io/assets/img/CoopersCloudLogoColor.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/cooperlutz.github.io/">Cooper's Cloud</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled  -->
			














<li>
	<a href="https://github.com/cooperlutz/cooperscloud" title="Follow on GitHub">
		<i class="fab fa-fw fa-github"></i>
	</a>
</li>































            <!-- Search bar -->
            
		</ul>
	</nav>

</header>

    <div class="content">
      <article >
  <header style="background-image: url('/cooperlutz.github.io/')">
    <h1 class="title">Search</h1>
    
  </header>
  <section class="post-content"><div class="search">
    <div id="search-results"></div>
    <p id="not-found" style="display: none">
        No results found.
    </p>
</div>


<script>
  window.store = {
    
      "2019-04-09-azuread-aadds-adds-html": {
        "title": "Azure AD, Azure AD DS, &amp; AD DS on Azure",
        "tags": "",
        "date": "April 9, 2019",
        "author": "",
        "category": "",
        "content": "What are these different services? When should we use one versus the other? Do they provide similar capabilities? There are a number of identity options within Azure and its easy to confuse the purposes and capabilities of each solution.Azure ADMany organizations today are already utilizing Azure AD and may not even realize it. Azure AD by default is a cloud based domain service that provides the ability to create and manage users and groups and provide access to Azure or Office 365. In the context of Azure, Azure AD is utilized in conjunction with Azure RBAC to control user access to different Subscriptions and Resources within Azure. Azure AD is almost a given today and is utilized in addition to Active Directory Domain Services, not as a replacement.AD DS on AzureHere I'm referring to AD DS (Active Directory Domain Services) running on Azure Virtual Machines, a service which should be a very familiar to most organizations. There are a few things to take into consideration when configuring Domain Controllers within Azure but overall the service itself behaves exactly the same as it would with your existing Domain Services. For a brand new Azure deployment, AD DS Domain Controller Virtual Machines are typically one of the first workloads to deploy. This comes down to treating Azure as an extension of your data center and providing Domain Service capabilities to your Azure workloads in the event that the connection back to your data center is dropped and to ensure that Azure workloads aren't having to traverse an ExpressRoute or VPN connection every single time they need to check into the domain. AD DS on Azure is almost a given for organizations that are already reliant on AD DS. Azure AD DSAzure AD Domain Services is a newer feature available within Azure that provides managed domain as a service capabilities. Think of it as PaaS version of Domain Controllers. Sounds really nice, right? A word of caution, as this service can trip you up if you don't utilize it correctly. It is important to remember - Azure AD DS is NOT a replacement or extension of your existing domain. Although it would be really nice to never have to build Domain Controller VMs in Azure, that is not realistic at this point in time for most organizations.So what is Azure AD DS? Azure AD Domain Services is a domain service that synchronizes Azure AD users, groups, and passwords, to a managed service available to Azure Virtual Machines. Once available, Virtual Machines can be joined to the managed domain and utilize Group Policy, users, and group membership similar to traditional Active Directory Domain Services.Users, Groups, and Passwords are synchronized from Azure Active Directory to the managed domain instance, but group policy is not synchronized.Only one instance of Azure AD DS can be deployed per Azure AD Tenant (no multi-region deployments)Azure AD DS is highly available within each instanceAzure AD DS is a separate domain, but can be synchronized with your existing domainGroup Policy is not synchronized to Azure AD DSGroup Policy Objects can be created within Azure AD DSDomain and Enterprise admin capabilities are not available for Azure AD DSAzure AD password hash synchronization is required for Azure AD DSAzure AD users and groups are synchronized to Azure AD DSExample ScenarioIn the following graphic portrays how each identity service may be utilized in a scenario of managing a single Azure Windows Virtual Machine.In this scenario, the Windows VM can be joined to either AD DS domain or my Azure AD DS domain, but not both. The option to join a Virtual Machine to one of these domains is one or the other situation.What do we do?With this information, the solution that makes sense for most organizations includes deploying AD DS Domain Controllers on Azure and utilizing Azure AD synchronization to manage resources and users within the Azure Portal. Azure AD DS is a great service but should be used for a specific use case.",
        "url": "/cooperlutz.github.io//2019/04/09/azuread-aadds-adds.html"
      }
      ,
    
      "2018-12-31-developing-custom-dashboards-html": {
        "title": "Developing Custom Dashboards in Azure",
        "tags": "",
        "date": "December 31, 2018",
        "author": "",
        "category": "",
        "content": "Whether you've been working with Azure for years or are just getting started, you'll often find yourself starting at the Dashboard blade as you work in the Azure Portal. Every time you login, as you're navigating around and working through various tasks, after you've spent your entire 8 hour day trying to build out or troubleshoot an application, the Dashboard will always be there along for the ride. Building a custom Dashboard can enable you to quickly consume relevant information, identify issues, and make navigating the Azure Portal a much more enjoyable experience. In this post we'll explore some of the ins and outs of Dashboard templates as well as some of the features available for working with Dashboards.Custom Dashboard SampleThis is the default Dashboard that I use for my personal Azure environment. I've kept the Dashboard simple, but effective, for my purposes. I've embedded my logo, links to some Azure documentation that I visit regularly, the \"All Resources\" tile to quickly access Resources I've recently been working with, an Application Insights availability test that monitors the availability of the cooperscloud.tech site, and an image of a Sample Azure application architecture.Methods for Creating and Developing DashboardsIn this post we'll focus on developing and working with Dashboards in code, but Azure provides numerous methods to customize your Dashboard within the Portal:- Using the Dashboard editor- Manually pinning Azure Resources to your dashboard- Developing a Dashboard in JSON and uploading to the portal- Auto-generating Dashboards that come pre-configured within certain Azure Services (i.e. Application Insights)Download Existing Azure DashboardsExisting Dashboards can be downloaded in JSON format from the Dashboard page. This feature provides the ability to manually customize a Dashboard and then save and re-deploy the Dashboard as code. This feature can be really useful when you want to quickly understand how a Tile is formatted before re-writing the code.Develop Custom Azure DashboardsAlthough the Dashboard editor is fairly easy to work with, once you can get the hang of defining Dashboards in code, you'll have much more flexibility in creating meaningful and reusable Dashboards. The code for the sample Dashboard in this post can be found here: https://github.com/cooperlutz/cooperscloud/blob/master/azure-dashboards/coopersclouddashboard.json.Within the sample code, the sections should look fairly familiar if you have previously worked with Azure ARM Templates. The Dashboard definition starts with a name, type, location, and API version, and we define all of our tiles within the Properties object.Within the properties object is a single \"lenses\" object where we define a \"0\" object, which contains a parts object, which identifies each of our tiles by number, and THAT's where we define our tiles. It's a little bit confusing but the reason it's currently defined in this manner is to provide capabilities for future updates to Dashboards (which is always exciting!) My guess is that the lenses will provide a sort of page feature that you can switch between within a single Dashboard (kind of like an image slider on a web page). However, this is purely speculation and my personal opinion of what I'd like to see. But for now, we get 1 Lense. If you'd prefer to just skip over all of the confusion, I've provided a template sample that you can start with: https://github.com/cooperlutz/cooperscloud/blob/master/azure-dashboards/baseDashboard.json. https://github.com/cooperlutz/cooperscloud/blob/master/azure-dashboards/baseDashboard.json.Taking a further look at the Tile definition, the first JSON object defined is the Tile's \"position\", giving us the ability to control the size and location on the Dashboard grid. The image below displays the Dashboard \"edit\" view and displays the Dashboard grid. The second part of defining our Tile is the \"metadata\" object, which is where we define the type and content of the Tile.The first tile defined in the Sample Dashboard is a Markdown tile which gives us the ability to create and format freeform text in Markdown syntax. In this case, I used this Markdown tile for the sole purpose of embedding my logo. Now in the case above for linking to a logo, I just linked directly to the image hosted on my website, but for the Sample Application Architecture tile, I link to an Azure Storage Account blob with a SAS token. In this way, I could link to proprietary images, such as application architectures deployed in my Azure environment, reference documentation to my applications, etc.Once we've defined all of the tiles in our Dashboard, all we have to do is save the file and click the \"Upload\" button from the Dashboard blade. We'll be prompted to choose the file to upload and then the Dashboard will be deployed and populated!Share Azure DashboardsOnce you've created a Dashboard that you'd like to share amongst others who are working in your Azure environment, you can deploy the Dashboard to a Resource Group so that it may be used by others.Click the \"Share\" button at the top of the \"Dashboard\" blade, then choose a name, subscription, and location. By default Azure will create a \"dashboards\" Resource Group for the Dashboard resource to be deployed to, but you can deploy it to a different RG if you prefer.Once the Dashboard is shared, other users will have the ability to switch to the Shared Dashboard under their Dashboard selector. Shared Dashboards also come with the ability to control which users have access to view the Dashboard.Azure Portal Home versus Dashboard ViewWith the introduction of the Azure Home page, you now have the ability to choose whether you'd prefer your default Azure Portal view to be Home or Dashboard. To change the preferred default Portal view, all you need to do is open the Settings gear icon in the top right of the Portal, and modify the \"Choose your default view\" setting.Although I do like the look and feel of the new \"Home\" and it has some great resources, it's currently geared more toward a \"first time logging in\" experience. I personally hope it evolves toward serving as a hub for news, developments, and releases within Azure in addition to the educational reference links.",
        "url": "/cooperlutz.github.io//2018/12/31/developing-custom-dashboards.html"
      }
      ,
    
      "2018-07-09-azure-management-groups-html": {
        "title": "Improve Subscription Management with Azure Management Groups",
        "tags": "",
        "date": "July 9, 2018",
        "author": "",
        "category": "",
        "content": "Organizations and individuals often utilize multiple Subscriptions across their Azure environment. Depending on the needs of an organization, these may be split up by department, life-cycle, business unit, etc., and result in one or hundreds of Azure Subscriptions. The more Azure Subscriptions we have, the more difficult it becomes to manage each Subscriptions access controls and Azure Policy, often resulting in Subscription sprawl. With the introduction of Azure Management Groups, we can now more effectively manage our Azure Subscriptions by grouping them into containers, similar to the way we group like Azure Resources into Resource Groups. Azure Management Groups ScenarioTo demonstrate Azure Management Groups, we will create the below hierarchy for our 3 Azure Subscriptions, which are segmented by life-cycle, Prod, Test, and Dev. In this case, we’ll create 2 Management Groups for “Prod” and “Testing”. We want to ensure that our Dev and Test Subscriptions have similar levels of access for our Developers, but we need to restrict Prod access.Azure Management Group Details \tAzure Management Groups can be assigned Access Controls and Azure Policies \tAzure Policy and access controls assigned to a Management Group are inherited by child Subscriptions and Management Groups \tA Subscription can be assigned to 1 Management Group \tManagement Groups can be renamed \tManagement Groups can contain multiple Subscriptions and/or Management Groups \tManagement Groups can be moved to other Management Groups \tNew Subscriptions are assigned to the Tenant Root Group Creating Our Azure Management Group HierarchyTo start building our Management Group hierarchy, we’ll begin by navigating to the “Management Groups” blade. We’ll start by enabling Azure Management Groups which will also create our “Tenant Root Group”, the root or highest level Management Group.  Create Azure Management GroupsNow we can create our child Management Groups. We’ll create 2 Management Groups per our above hierarchy, “Prod” and “Testing”. Our Management Groups are made up of a name and ID. We will correlate these names and IDs to our “Prod” and “Testing” environments.              Assign Subscriptions to Azure Management GroupsWith both of our Management Groups created, we need to assign our Subscriptions to our Management Groups. Under our “Testing” Management Group, we’ll click on the “(details)” link. Within our “Testing” Management Group, we can assign access control, Azure Policy and assign any child Management Groups or Subscriptions. We’ll click on the “+ Add subscription” button to assign our “Dev” and “Test” Subscriptions. A drop-down will allow us to choose from our list of available Subscriptions.IMPORTANT NOTE: Existing access controls assigned to our Subscription will be removed once assigned to the new Management Group. Therefore, if we are migrating any subscriptions to this new model, we want to first assign their existing permissions set at the Subscription level, to the Management Group level. When migrating to Azure Management Groups, we want to ensure that we don’t lose any permissions. We’ll copy this same process with our remaining Subscriptions and we’ve now successfully created our defined Management Group hierarchy.",
        "url": "/cooperlutz.github.io//2018/07/09/azure-management-groups.html"
      }
      ,
    
      "2018-05-29-mastering-arm-templates-3-html": {
        "title": "Mastering ARM Templates Episode 3 - Deployment",
        "tags": "",
        "date": "May 29, 2018",
        "author": "",
        "category": "",
        "content": "In previous episodes we took a look at the basics of ARM Templates, and some of the methods of developing ARM Templates. In this installation, we’ll take a look at common deployment options.Deployment StrategyWhen it comes to determining a standard deployment strategy for ARM Templates, there are a number of options, but the goal is to choose a strategy that fits the audience and situation. In certain circumstances it might make sense to mix and match these options to fit our overall deployment strategy.To help with this decision, I’ve created a flowchart based on my own experiences and personal opinions: Deployment ConceptsResource GroupsTemplates are always deployed to a Resource Group, and Resource Groups cannot be created via ARM Templates. This means that the target Resource Group must exist prior to template deployment. Template ValidationPrior to deploying a template, we can validate the template code to ensure there are no syntax errors or missing values. This is done by default when deploying templates through the Azure portal, but this can also be done via PowerShell.Test-AzureRmResourceGroupDeployment Deployment ModeTemplates can be deployed in “incremental” or “complete” modes. The default deployment mode is incremental, specifying that the resources deployed to the target Resource Group are incremental changes or additions to the Resource Group. In contrast, when deploying in complete mode, we are specifying that the template deployment is the desired final state for the target Resource Group, and resources that exist in the target Resource Group that are not defined by the template will be removed. Utilizing complete mode should be used only when specifically needed as this can result in resource loss. Azure Portal Resource DeploymentOne-time ARM Template deployments can be achieved by creating a new “Template deployment” resource within the Portal. It can be a valuable tool if we just want to test something out, but prevents us from easily redeploying, reusing, or managing our templates. Within the “Template deployment”, we can start with a sample or build our own custom template. Here we can paste in the contents of our template, generally this consists of the “azuredeploy.json” contents. After saving the template, we can input our parameters for the template deployment and then just click “Purchase” to deploy. PowerShellFor those comfortable with PowerShell, deploying templates via PS scripts is fairly easy and there are some great methods to handle template deployment via PowerShell.The first option is to utilize the “New-AzureRmResourceGroupDeployment” script which provides the ability to reference a template and parameters file to be deployed to Azure. We can even append “-Mode (complete or incremental)” to specify our desired deployment mode. In the following example, a mode is not specified, resulting in the use of “incremental” mode. The previous script is fairly easy to use and doesn’t require much input, but there is another deployment script that provides much more flexiblity. Within the “Azure QuickStart Templates” repository, there’s a provided script Deploy-AzureResourceGroup, which will do things like validate the template prior to deployment and create a new Resource Group if the one referenced doesn’t exist. Templates BladeThe “Templates” blade within the Azure Portal is currently a preview feature that provides the ability to store, share, and deploy commonly used templates. This is a great method for easily creating common resources as an alternative to Azure Marketplace resources. For members of the team who aren’t working with ARM Templates on a regular basis but need to deploy a standardized resource, the Templates Blade is a great option. The biggest drawbacks of this method are the inability to easily nest or reference parameters files. When creating a new template, a name and description are provided to specify the templates purpose or additional details. Now we’ll just paste in the code that’s stored in our “azuredeploy.json” file containing our resource definitions. We’ll click “OK” and “Add”. The template will show up under the Templates blade and is available for deployment. At the top of the Template, we’ll click the “Deploy” button. After clicking “Deploy”, we receive the friendly parameters page that will allow us to input the parameter values for deployment. Visual StudioVisual Studio can be an extremely powerful tool for handling ARM Templates. We can develop, manage with source control, and deploy, our ARM Templates all within the same tool. The graphical interfaces used during the deployment process can help prevent copy/paste errors that may occur when deploying via PowerShell and we get the full value of specifying predefined parameter files.To deploy a template in Visual Studio, we’ll start by creating a new project. The Azure Resource Group project type can be found under “Visual C#” &gt; “Cloud”. We’ll provide a name for our project and click “OK”. After creating our new project, a second interface will allow us to choose which template we’d like to start with. In this case, we already have the code we want to use so we’ll just choose “Blank Template”. Now all we have to do is copy our template files into our new Visual Studio project. Once we have the template files added to the project, we can right-click on our Visual Studio project and click “Deploy”, and select “New…”. The deployment interface allows us to choose the Subscription, Resource Group, and our Template and Parameters file. This is a really nice feature when we have multiple parameters files stored in the project and want to easily select the appropriate parameters file rather than copy/pasting or typing them out into a PowerShell deployment script. Deploy to AzureAzuredeploy.net is a great tool to easily deploy ARM Templates from a public GitHub repository to your Azure environment. Azuredeploy.net cannot be used for private GitHub repositories and for this reason doesn’t make sense for an organization’s use. However, this is great feature for publicly shared templates, allowing others to easily deploy a template into their own Azure environment. In this case, we can navigate to the Cooper’s Cloud GitHub repository and deploy this N-Tier template into any Azure Subscription with the click of a button.To add the “Deploy to Azure” button within a public GitHub repository, a README.md file is added to the repository containing the following string:[![Deploy to Azure](https://azuredeploy.net/deploybutton.png)](https://azuredeploy.net/)![image alt text](/cooperlutz.github.io/assets/img/AzureDeploy.png)",
        "url": "/cooperlutz.github.io//2018/05/29/mastering-arm-templates-3.html"
      }
      ,
    
      "2018-04-26-mastering-arm-templates-2-html": {
        "title": "Mastering ARM Templates Episode 1 - Development",
        "tags": "",
        "date": "April 26, 2018",
        "author": "",
        "category": "",
        "content": "In the previous episode, we took a look at the ARM template schema, some of the tools that will help get you started in your ARM template journey, and deployed our first template. In this installation, we’ll take a deeper dive into some of the development methods and strategy.Define Template ScopeBefore developing a template, it’s important to define the scope of the template. In extreme cases, this could be the difference between the idea of an “infrastructure in a box” where you deploy a single template for your entire infrastructure vs. deploying separate templates for each resource type as you would in the Portal. Like most things, I think the best strategy is somewhere in the middle, and depends on your needs.Generally, a good start is to begin your scope at the Resource Group level (however, it is possible to deploy to multiple Resource Groups). Some other things to think about when scoping the template are the region, life-cycle, deployment frequency, resource types, and purpose, of the resources.For example, we may have an application that requires multiple Virtual Machines with separate roles. The architecture calls for 2 front-end servers, 2 application servers, and 2 back-end servers. You could deploy all 6 servers with a single template, but that could get convoluted and doesn’t provide the flexibility to easily redeploy a single tier. In this case, we can scope the templates to the tier level and separate out the 3 tiers into 3 templates.Define Resource Property ValuesWith the template scope defined, the next step is to define the resource property values. These are the settings applied to Azure resources, like a Virtual Network’s address space, or a Virtual Machine’s OS.Parameters can be used to define values that can change between deployments. The more parameters defined, the more dynamic the template becomes. Resource names are a great example of values that are generally set as parameters.Variables can be used to reference hard-coded values that can be used multiple times throughout the template and are not going to change throughout deployments. However, defining a resource property as a variable allows us to easily change the value at a later point in time if needed.Hard-coded values can be used to define settings that are not changing between deployment and are not going to change.Define a Folder StructureDetermining an organized folder structure can be extremely valuable when developing your templates. As you start digging into more complex templates with multiple references, it’s easy to lose track of your files and end up with code sprawl.Generally, I start by creating a root folder with a name that specifies the purpose of the template.Inside the root folder, I place the template “azuredeploy.json” file, along with dedicated folders for the additional files that will be referenced by the template.  The “parameters” folder for instance, contains any of the parameters files that are used to deploy the template. Multiple sets of parameters files can be stored inside this folder for separate deployments.Understanding ARM API VersionsEach resource defined in a template contains an API version reference . Understanding how Azure manages these API versions can save you a lot of headache. Azure releases new API versions that include the latest features or settings available for a resource. However, it’s important to note that when a new API version is released, only certain Azure resources will be included in the release. This means that we can’t just grab the latest API version available and use that value for every resource in the template. It’s important to keep track of these API releases and ensure that templates are kept up to date.The Azure team maintains a public GitHub repository of the ARM API versions available.https://github.com/Azure/azure-resource-manager-schemas/tree/master/schemasAdditionally, you can download the deployment schema from the link below and search for the specific resource type and API versions available for that resource.https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json Development Scenario and MethodsThere are multiple options for developing templates. To demonstrate these options, we’ll create an ARM template to deploy the following architecture. In this example we’re assuming that we have a server based web application that will utilize an Azure SQL database at the data tier. QuickStart TemplatesWe’ll start by browsing to the Azure QuickStart Template repository that’s hosted on GitHub. From here, we can search through sample templates for one that suits our needs. One of the sample templates available (shown below) will serve as a great starting point will account for the web application server.Browse to the following location and download the “azuredeploy.json” and “azuredeploy.parameters.json” files.https://github.com/Azure/azure-quickstart-templates/tree/master/101-1vm-2nics-2subnets-1vnetAzure Generated Automation Script TemplatesWith our web application server taken care of, we need to add in our SQL Server and Database. For these two components, we’ll download the Automation Script template that Azure generates for existing resources.We’ll start by provisioning an Azure SQL instance within the portal. Once the SQL deployment is complete, we’ll navigate to the SQL Database resource and browse to the “Automation Script” blade. It’s important to note that the Automation Script will consist of all resources within the same Resource Group.At the top of the Automation Script blade, we can download the template files to our local machine.The downloaded template contains a number of reference files:deploy.ps1 - PowerShell deployment scriptdeploy.sh - Azure CLI deployment scriptdeployer.rb - Azure Ruby SDK deployment scriptDeploymentHelper.cs - C# class to deploy the templateparameters.json - parameters file for the deploymenttemplate.json - core template file containing all of the resources to be deployedFor now, all we’re going to need from these files are: parameters.json and template.json.Stitching the Templates TogetherNow we need add the Azure SQL components into our template.When we open up the downloaded template, we find that it consists of a number of resources outside of the Azure SQL Server and Database. In this case these resources include some of the Azure SQL settings that are provided by default and weren’t necessarily defined when we created the database in the Portal. For our purposes, we’ll remove all the resources and parameters outside of the SQL Server and Database. Then we can just copy/paste these sections into our existing template. Template Reference DocumentationIt’s just about time to test our template but let’s validate our downloaded template against the reference documentation. Navigate to the Azure reference documentation (found here) and browse under the “Reference” section to find SQL &gt; Servers. In comparing the downloaded Automation Script template to the reference documentation, we notice that the ”administratorLoginPassword” setting is missing from our template. Since the Automation Script does not download the secure string value, the setting is omitted from the downloaded template. It’s imperative to set a password on the database, so we’ll add this property into our template. Currently, our template consists of the Azure QuickStart Virtual Network, Subnets, Virtual Machine, Network Interfaces, and the Automation Script downloaded SQL Server and Database which we validated against the template reference documentation. Let’s take a look at this template and deploy it into Azure.https://github.com/cooperlutz/cooperscloud/tree/master/arm-templates/ntier-VM-AzureSQLWe have all of the components accounted for - as laid out in our diagram - so let’s try deploying it:Success!Our template deployed successfully. Now we can take a look at our Resource Group in the Azure Portal and find that it consists of all the resources defined in our architecture.",
        "url": "/cooperlutz.github.io//2018/04/26/mastering-arm-templates-2.html"
      }
      ,
    
      "2018-04-03-mastering-arm-templates-1-html": {
        "title": "Mastering ARM Templates Episode 1 - The Basics",
        "tags": "",
        "date": "April 3, 2018",
        "author": "",
        "category": "",
        "content": "Getting Started with ARM TemplatesI’ve spent a considerable amount of time developing ARM Templates and have been working to put together a series of posts to help you master ARM Templates, whether you’re just getting started with Azure or have been developing ARM Templates since their inception. Beyond simplifying your deployments, you can learn so much about Azure’s inner workings and more complex features through ARM Template development. ARM Templates are Azure’s built-in infrastructure-as-code (IAC) toolset. This means that I can create or modify resources within Azure (Virtual Machines, Virtual Networks, etc.) by creating a configuration file and letting Azure handle the provisioning. ARM Templates enable you to create consistent and repeatable deployments within your Azure environment.  ARM Templates BasicsARM Templates are defined using JSON (JavaScript Object Notation), a structured language that consists of data referenced as name/value pairs, stored as objects. Let’s take a look at some of the components that make up an ARM Template (click image to enlarge).  ARM Template Resourceshttps://github.com/Azure/azure-quickstart-templatesThe Azure team has provided a public GitHub repository with a number of reference ARM Templates to get you started. This is where I always start when developing a new template. Development ToolsVisual Studio CodeVS Code is a light-weight editor that’s perfect for developing ARM Templates. VS Code has built-in integrations with  This is my recommended tool for a large majority of your ARM Templating needs, and one of my favorite features is the ability to auto-format JSON! Visual StudioVisual Studio has built-in auto-formatting and some other great features for helping develop and deploy complex ARM Templates. Using Visual Studio can be overwhelming for getting started but I will provide plenty of information and resources about Visual Studio in the coming weeks. Armviz.ioArmviz is a browser-based ARM Template development tool. Armviz has a fairly decent feature that allows you to generate a design view of the Azure resources inside your template. Big catch for this tool, its a Public project hosted on GitHub that hasn’t been updated in a couple years. I’ll use this tool for quick and simple templates sometimes, but don’t recommend it for every day use. Version Control Tools - GitHub, VSTS, BitbucketUsing a version control service is the recommended method of storing ARM Template code. If you don’t have much of a development background these tools can take some getting used to, so I wouldn’t worry about them too much when getting started. Deployment OptionsAzure Portal resource deployment - within Azure you’re able to perform a one-time deployment of an ARM Template by creating a new resource “Template deployment”.PowerShell - the AzureRM PowerShell modules have a “New-AzureRMResourceGroupDeployment” command to deploy templates.Templates Blade - the Azure Portal has a “Templates” blade that allows you to store your templates within Azure and easily deploy.Visual Studio - one of the value propositions for using Visual Studio to develop ARM Templates is the ability to deploy your template directly to Azure.Deploy to Azure - azuredeploy.net is a great tool to easily deploy ARM Templates from a public GitHub repository to your Azure environment. Azuredeploy.net cannot be used for Private GH repositories. First ARM TemplateWe’ll start with an ARM Template that creates a new VNet with 2 Subnets.To start, log into Azure and then browse to the following link:https://github.com/cooperlutz/cooperscloud/tree/master/arm-templates/network-VNet Deploy to AzureClick the Blue “Deploy to Azure button” provided in the GitHub link. Configure Settings \tDirectory and Subscription should refer to your Azure account information. This will be auto-populated since you're already logged in. \tResource Group - you may choose to use an existing Resource Group, or \"Create New\"  and provide a \"Resource Group Name\" if you don't already have one in your subscription. \tVirtual Network name - this is auto-populated using then \"Default Value\" in our template, seen here: After filling out the settings, click “Next” Click Deploy Deployment CompleteAfter the deployment has completed, click the “Manage” link or open your Azure Portal. Review Deployment in Azure PortalOur Virtual Network has successfully been deployed to Azure. It contains the two subnets that our template defined, along with the proper network address spaces.",
        "url": "/cooperlutz.github.io//2018/04/03/mastering-arm-templates-1.html"
      }
      ,
    
      "2018-03-14-cortana-and-azure-html": {
        "title": "Cortana Skills and Azure",
        "tags": "",
        "date": "March 14, 2018",
        "author": "",
        "category": "",
        "content": "I received a “virtual assistant” as a gift this year and while I enjoy listening to music and quickly checking the weather forecast (spoiler: its always cold in Chicago), I love the idea of bringing the virtual assistant into the workplace. This week I decided to build learn more about building custom “Skills” and decided to put this to the test with Cortana and Azure administration.I quickly came across the Cortana Dev Center, which provides an easy to use language and tool-set to develop Cortana skills. Rather than using C# or other programming language, Cortana Dev Center Skills are programmed using Semantic Composition Language (SCL). This is a great introductory programming language because its easy to read and understand.Here’s a quick high-level architecture of what we’ll be deploying: The ScenarioAs someone who spends most of my days living inside the Azure portal, I thought it would be great if I could delegate some of my tasks to Cortana. I figured it would be cool if I could just ask Cortana to “fix this error”, but decided to set my sights a little lower…So I imagined myself in the middle of lunch and receiving an email that I need to restart a VM ASAP. I pictured myself running to my computer, logging into Azure, finding the VM, performing a restart, confirming the machine comes back up, and then moving on, fairly simple process that takes maybe 5-10 minutes out of my lunch? But what if I could do it in 10 seconds….. Create a Cortana Skill to Restart an Azure VMCreate a new Cortana BotletStart by signing into the Cortana Dev Center and create a new Cortana Skill. Follow the steps provided and fill out the information requested. Add the Botlet codeAdd the Code that will control the Skill. The code I created can be found here:https://github.com/cooperlutz/cooperscloud/blob/master/cortana-scl/botlet.txt Add a new Runbook to your Azure Automation AccountAdd a new Runbook to your Automation AccountPaste the Runbook code from here:https://github.com/cooperlutz/cooperscloud/blob/master/powershell-scripts/WebhookRunbook.ps1 Create the Runbook WebhookFrom within the Runbook, navigate to the Webhook and Create a New webhook. Give your webhook a name, and expiration. The URL will be autogenerated.Add a new botlet serviceAdd a new service to the botlet solution Add a description to the service and an image if desired Choose the “I have a web service” option, and paste the Runbook Webhook URL. You’ll need to remove the “?token=asdf….” portion, but make sure you save that portion for the next step. Update the Webhook URL to include the “?token=asdf1234…..” Add an action to the Service. Add the Action Parameters, in this case, VM name. Test the solution by chatting with Cortana. Sorry something went wrong? I spent about 20 minutes chasing this error before I realized that the Runbook was in fact executing and I seemed to be receiving a false positive. I believe the error was due to the Webhook not sending a result back.Here we see the output of our Runbook Success! Next StepsAzure Bot Services resources are available to deploy more robust chat bots as an Azure Web App or Azure Function.",
        "url": "/cooperlutz.github.io//2018/03/14/cortana-and-azure.html"
      }
      ,
    
      "2018-03-05-azure-hybrid-workers-html": {
        "title": "Azure Hybrid Runbook Workers are Awesome",
        "tags": "",
        "date": "March 5, 2018",
        "author": "",
        "category": "",
        "content": "Azure Hybrid Runbook Workers enable Azure Automation Runbooks to run in a local context (OS/Server level). The Hybrid Runbook Worker’s functionality is achieved through a combination of Azure Log Analytics, Microsoft Monitoring Agent, and Azure Automation Runbooks.Why Are Hybrid Runbook Workers Awesome?Central Management of Scripts - store all automation scripts needed across the environment, in one location.Hybrid Architecture - Hybrid Runbook Workers are achieved with a mix of serverless / server architectures.OS Agnostic - works on Windows or Linux with Python / PowerShell Runbooks.Runbook Execution - execute local scripts via Runbook Schedules, Webhooks, or Logic Apps.Scalable - a Hybrid Worker Group can contain one or more VM, and an Automation Account can contain one or more Worker Group.Cost Effective - smaller VM sizes can be utilized to keep costs low, I generally use a Standard_DS2_v2. Depending on your needs, the VM can be auto-shutdown to around scheduled Runbook tasks.Watcher Tasks - create custom scripts to monitor services, files, tasks, etc. Test ScenarioNow we’ll put this to the test. For the test scenario, we’ll configure the Hybrid Worker to restart a Windows service, Print Spooler. Create a Virtual MachineFirst we’ll need to create a Virtual Machine to be configured as our Hybrid Runbook Worker. My personal recommendation is to use a dedicated Windows / Linux VM to run the Hybrid Worker. For this test I created a “Standard_B1s” VM. Configure Log Analytics OMS WorkspaceIf you don’t have an existing Log Analytics OMS Workspace, we’ll need to start by creating one.Navigate to “Log Analytics” in the Azure portal and add a new Workspace. We need to add the “Automation and Control” solution to our OMS Workspace. Navigate to the OMS Portal and open the Solutions Gallery. Within the OMS Solutions Gallery, select “Automation &amp; Control”. The solution will provide a warning that the Workspace needs to be configured. Specify the Azure Automation Account you will be using to run your Hybrid Worker. If you don’t already have an Automation Account, you can create a new one from here. Configure the Hybrid Runbook Worker ServerLogin to your server and open up PowerShell as administrator.Run the following install script to add the New-OnPremiseHybridWorker script.Note if you are not using Windows Server 2016, you may need to install Windows Management Framework 5.0 to utilize necessary PowerShell scripts.Install-Script -Name New-OnPremiseHybridWorker -RequiredVersion 1.0 Next, run the script you just installed and reference the Workspace you created earlier. You’ll be asked for a few additional parameters, which are referenced below.New-OnPremiseHybridWorker.ps1  -WorkspaceName &lt;NameOfOMSWorkspace&gt;The script will ask you to input the additional parameters needed:And that’s that, the server configuration is complete! Create the RunbookCreate a new Runbook within your Azure Automation Account. Now we’ll add our PowerShell script that will run locally (i.e. not AzureRM modules).Note: if using non-standard modules, the modules must be installed on the Hybrid Worker VM before executing.Test the SolutionStop Print Spooler on the Virtual Machine. Start your Runbook and specify that it will be run on the Hybrid Worker.Success!After the Runbook task has completed, Print Spooler is running on the server. Azure Automation Watcher TasksNow we’ll use Azure Automation Watcher Tasks to monitor the Spooler service and automatically execute the “Restart-Service” script if the service is not in a “running” state.Add a Watcher and Action RunbookStart by adding the following Runbooks to your Automation Account:Watch-ServiceProcess-ServiceFor this section, the scripts provided are meant to be more robust and account for the ability to run scripts against other servers in the environment. However, to fully utilize the script, we’ll need credentials with the ability to open a remote PowerShell session. Side Note:Here are some other great Watcher examples provided by Microsoft to watch a folder for new files:https://gallery.technet.microsoft.com/scriptcenter/Watcher-runbook-that-looks-36fc82cdhttps://gallery.technet.microsoft.com/scriptcenter/Watcher-action-that-b4ff7cdf Add the Local VM Credentials to Azure AutomationNavigate to the “Shared Resources” section of the Automation Account and add a new credential. For testing purposes, I’m just adding the local admin account.Configure the Watcher TaskNavigate to the “Watcher tasks” section within your Automation Account, and click “Add a watcher task”. Specify a name for the task and the frequency to run (1-59 in minutes). Then select the “Watch-Service” Runbook as the “Watcher” and input the service name parameter (in this case, “Spooler”) and computer name parameter (in this case, “localhost”). For the “Action”, select the “Process-Service” Runbook, the parameter should be left blank as the value will be passed from the Watcher task. Once again, we manually stop the Spooler service and wait for our watcher task to execute. Success!",
        "url": "/cooperlutz.github.io//2018/03/05/azure-hybrid-workers.html"
      }
      ,
    
      "2018-02-19-azure-automation-ipam-html": {
        "title": "Azure Automation and Table Storage - Creating a Basic Azure IPAM Solution",
        "tags": "",
        "date": "February 19, 2018",
        "author": "",
        "category": "",
        "content": "I wanted to provide a basic demo of Azure Automation, Azure Storage Explorer, and the use of Storage Account Tables, because I think all three are extremely valuable to any Azure Administrator or Developer. Personally, I think its more fun to provide a working solution that fully utilizes the features rather than regurgitate information that’s already available, so I came up with this.The ProblemManaging, planning, and organizing address spaces within Azure can get quite cumbersome and is something that I believe could be improved upon in the portal. I find myself clicking in and out of VNets, their subnets, checking outdated spreadsheets, and trying to keep everything updated once there are too many cooks in the kitchen. I chose to build this solution in Azure Automation and store my data in a Storage Account Table. Here’s the final product:The SolutionI’ve provided an Azure Automation Runbook, and Local PowerShell versions of this solution which can be found on my GitHub or PowerShell Gallery:https://github.com/cooperlutz/cooperscloud/tree/master/powershell-scripts/Generate-AzureIPAMTablehttps://www.powershellgallery.com/packages/Generate-AzureIPAMTable/Table StorageStorage Account Tables provide simple storage of structured datasets. The Table is made up of “entities” which each contain a “Partion” and “Row” Key. The “ParitionKey” serves as a group of “entities”, while the “RowKey”  serves as the unique identifier for the “entity”.  The “RowKey” must not be a repeated more than once in a “Partition”.Tables can not be viewed in the Azure portal, but Microsoft has provided a free tool “Azure Storage Explorer”, which allows for an Azure administrator to view their tables, blobs, file shares, and queues. Azure Storage Explorer also allows you to modify, add, and delete data stored in a Storage Account.I like to think of them as a mix between a database table and a spreadsheet.The ScriptI wrote this script in a local PowerShell instance and then converted it to Azure Automation, my preferred method because its generally a little bit easier to troubleshoot and allows me to run portions of code rather than troubleshooting the entire script in the Azure Automation Test Pane.I started by defining the resources I wanted to display in this solution:  Virtual Networks  Subnets  Public IPs  Reserved Address Spaces - something that Azure does not provide a solution for, but I think would be a nice to have. I think of this as a placeholder for a planned space, or defining my on premises address range.From here I was able to come up with a script that would loop through all of the Public IPs, Virtual Networks, their Subnets, and then added a test output for the Reserved Spaces.I decided I also wanted to add functionality that would calculate my hosts, host IP, broadcast IP, and separate out the address length. This was accomplished utilizing the PSipcalc script created by Svedsen Tech, which I added in as a Function. Big thanks to him for that piece of art. His script also provides some features that I’d love to implement at a later version, specifically around calculating and displaying any address overlap.Outputting the data was tricky and something I had to try out a few times. I wanted to be able to quickly organize my output table by the “RowKey” in a fashion that would first show the VNet, then its Subnets immediately following. I accomplished this by iterating through the Vnets and assigning them a “RowKey” of “Vnet###”, and then iterating through each Subnet and assigning them a “RowKey” of “VNet###” + “Subnet###”. Now I’m able to view the data in a more understandable way by sorting by “RowKey” descending.Here’s a small subset of the code to display some the data retrieval, “RowKey” iteration, PSipcalc function calls, and output:\\# Get the table, PIPs, and VNets$table = Get-AzureStorageTable -Name $tableName -Context $saContext$vnets = Get-AzureRmVirtualNetwork$publicIPs = Get-AzureRmPublicIpAddress -ErrorAction SilentlyContinue\\# Vnets loop - get the Vnet data and its relevant subnets.Write-Verbose \"Populating VNets and Subnets...\"foreach ($vnet in $vnets) {  \\# Set Val2 to 1 to re-initiate the subnet rowkey $val2 = 1 \\## Get the Virtual Network's range and run it through PSipcalc $vnetAddressSpace = Get-AzureRmVirtualNetwork -Name $vnet.Name -ResourceGroupName $vnet.ResourceGroupName | select AddressSpace $vnetAddressSpace = $vnetAddressSpace.AddressSpace.AddressPrefixes $rangeInfo = Psipcalc -NetworkAddress $vnetAddressSpace\\# Add the table row for the Vnet Add-StorageTableRow -table $table -partitionKey \"VNet\" -rowKey (\"Vnet\" + (\"{0:d3}\" -f $val++)) -property @{` \"VirtualNetwork\" = $($vnet.Name); ` \"Type\" = \"Range\"; ` \"Name\" = $($vnet.Name); ` \"PublicIpAllocationMethod\" = \"\";` \"NetworkLength\" = $($rangeInfo.NetworkLength);` \"IP\" = $($rangeInfo.IP);` \"TotalHosts\" = $($rangeInfo.TotalHosts);` \"Broadcast\" = $($rangeInfo.Broadcast); ` \"AddressSpace\" = $($vnetAddressSpace); ` \"ResourceGroupName\" = $($vnet.ResourceGroupName)` }\\# Loop through all subnets within a vnet and output these to a table row $subnets = Get-AzureRmVirtualNetwork -Name $vnet.Name -ResourceGroupName $vnet.ResourceGroupName | select subnets $subnetCount = $subnets.Subnets.Name.Count For ($i = 0; $i -lt $subnetCount; $i++) {  $rangeInfo = Psipcalc -NetworkAddress $subnets.Subnets\\[$i\\].AddressPrefix\\# Add the table row for each vnet Add-StorageTableRow -table $table -partitionKey \"Subnet\" -rowKey (\"Vnet\" + (\"{0:d3}\" -f ($val-1)) + \"Subnet\" + (\"{0:d3}\" -f $val2++)) -property @{` \"VirtualNetwork\" = $($vnet.Name); ` \"Type\" = \"Range\"; ` \"Name\" = $($subnets.Subnets\\[$i\\].Name); ` \"PublicIpAllocationMethod\" = \"\";` \"NetworkLength\" = $($rangeInfo.NetworkLength);` \"IP\" = $($rangeInfo.IP); ` \"TotalHosts\" = $($rangeInfo.TotalHosts); ` \"Broadcast\" = $($rangeInfo.Broadcast);` \"AddressSpace\" = $($subnets.Subnets\\[$i\\].AddressPrefix); ` \"ResourceGroupName\" = $($vnet.ResourceGroupName)` } }}Azure Automation and Storage Account Table Walk ThroughCreating the Storage AccountI generally like to recommend that an organization establish a general purpose Storage Account to be used for shared resources that Azure uses to integrate some of their services, like Azure Cloud Shell, Azure ARM Templates archives, or other resources that Azure admins regularly use. In this case we will establish a general purpose Storage Account that will store our Table Storage output.I choose LRS for these general purpose Storage Accounts because I’m not too concerned about losing the data or not being able to access it during an Azure outage.That’s it! Our Storage Account is ready to be used.Configuring the Azure Automation AccountStart by searching for the Automation Account blade in Azure.Click to add a new automation account.Add Automation AccountCreate Azure Run As account - I choose “Yes” to this feature as my automation account deployment will generate an AzureAD account that will have Contributor access to my Azure resources. You can navigate to the “Run as accounts” under your Automation Account’s “Account Settings” to view its generated display name, Application ID, and Roles, and other relevant information. It is possible to modify the level of access this account has after it is generated.Updating ModulesStart by viewing the default PowerShell Modules added to the Automation Account. The default modules are very early versions, so we want to update these to latest. The “Update Azure Modules” button at the top will quickly update all Modules to latest.Adding ModulesOnce our modules are updated, we need to add a few from the gallery for the runbook we are about to deploy. Navigate to the gallery and search for the needed modulesAzureRmStorageTableAzureRM.NetworkClick OK to add the module to your Automation Account.Handling Module Dependency IssuesUpon imporing the “AzureRM.Network” module, I’ve ran into a dependency issue with “AzureRM.Profile”. Although I updated all of my Azure modules, I ended up with 4.2.0. I’ve found the best way to combat this is with the following method:From the Modules blade, click on the “AzureRM.Profile” module, and then choose to delete it.Once deleted, the module version will default back to the lowest version.Navigate to the online PowerShell Gallery, search for the needed module, and select it.Click the “Deploy to Azure Automation” button.Select your Automation Account and click OK.Once the import has completed, return to the Automation Account and check the “Modules” blade, the AzureRM.Profile version should now show as 4.3.0.Now we can return to the gallery and attempt to import the AzureRM.Network Module. This time we are not met with any dependency warning. Click OK to import the modules.Deploying the RunbookNavigate to the PowerShell Gallery where the script is hosted. Click the “Deploy to Azure Automation” button to add it to your Automation Account.Select your Automation Account and click OK.Navigate back to your Azure Automation Account and select “Runbooks”. We see that the “Generate-AzureIPAMTable” runbook has been added. Select the runbook.From here we can make edits to the code, delete the runbook, add a schedule to automatically run our script, or review past executions. First we will click “Edit” and then choose “Publish” to make the Runbook available for execution.After publishing, we can run the script for the first time. Click “Start” to execute the script.Enter the resource group of the storage account, and the storage account name, then click OK.We can click on the “Output” to view the running details of the script.Once completed we will move on to viewing our Table’s data.Viewing the Storage TableDownload Storage Explorer from MicrosoftConnect to your Storage Account either by logging into Azure or providing the Storage Account name and key.Once connected, we see our table has been generated with our Azure IP resources.You can change the column options to make things a little friendlier.Complete!",
        "url": "/cooperlutz.github.io//2018/02/19/azure-automation-ipam.html"
      }
      ,
    
      "2018-02-10-point-to-site-vpn-html": {
        "title": "Certificate Challenges with Multiple Point-to-Site VPN Gateways",
        "tags": "",
        "date": "February 10, 2018",
        "author": "",
        "category": "",
        "content": "I ran into an extremely common issue with a Point-to-Site configuration with a not so common resolution. The Point-to-Site configuration guide provided by Microsoft is pretty easy to follow. Microsoft provides specific instructions and recommendations and I’ve followed this guide on numerous occasions.In this particular instance, I needed to configure a Point-to-Site connections between two separate VPN Gateways, all existing in the same subscription/region.I created a Root and Client certificate using PowerShell and uploaded the Base-64 .cer from my Root certificate to both of my test VPN Gateways. Copy and pasting directly from Notepad as most of us generally do:The certificate uploaded to both of my “test” gateways and I was able to configure the Point-to-Site connections from both of these gateways.The ProblemProduction deployment was the next step. Everything was going just fine until it came to testing the connections. I had already uploaded the certificate, set my address space, and downloaded the client for both gateways. I was able to connect to “Gateway01” just fine, but I received an error when trying to connect to “Gateway02”.A certificate could not be found that can be used with this Extensible Authentication Protocol. (Error 798)This issue usually results from not creating your certificates correctly or not having them installed to the correct certificate store (they need to be located in the Personal store as opposed to the Computer). I was a little unsure about this instance because “Gateway01” was using the same exact Root and Client certificate, and I already had my connection in place. Either way, I went ahead and recreated my Root and Client certificates, uploaded them to both of my gateways, and re-downloaded the VPN client. Tried connecting to my gateways and…..A certificate could not be found that can be used with this Extensible Authentication Protocol. (Error 798)Ok, well this was frustrating. So based on the error I received I was confident that the Root certificate had to be the issue. I wondered if it was something about the way the certificate was pasted within the Point-to-Site configuration. What if that “Enter” character that copied over from the Base-64 .cer file was pasting incorrectly into my P2S certificate line. I tested this theory out by reformatting my certificate to look a little something like this, making sure not to include the “BEGIN” and “END” sections of course:So essentially I was uploading the certificate without any spaces or strange “Enter” characters that could have been copied over from the generic certificate format. I went to re-upload the certificate to my “Gateway02” P2S configuration and sure enough I was met with an error:Operation nameWrite VirtualNetworkGatewaysTime stampEvent initiated byError codeVirtualNetworkGatewayDuplicateVpnclientRootCertificateMessageVirtual Network Gateway /subscriptions/SubscriptionId/resourceGroups/ResourceGroupName/providers/Microsoft.Network/virtualNetworkGateways/VPNGateway02cannot have same certificate used across two vpnclient root Certificate elements. Certificate for/subscriptions/SubscriptionId/resourceGroups/ResourceGroupName/providers/Microsoft.Network/virtualNetworkGateways/VPNGateway01/vpnClientRootCertificates/CertName and/subscriptions/SubscriptionId/resourceGroups/ResourceGroupName/providers/Microsoft.Network/virtualNetworkGateways/VPNGateway02/vpnClientRootCertificates/CertName are same.How strange that Azure hadn’t caught this based off the way I had been copy/pasting the certificate previously. And what about my test gateways that successfully used the same Root certificate? Possibly just a fluke? Maybe my copy/paste skills are lacking? Whatever the case may be, I was excited that I found an error and decided to just create separate Root certificates for each VPN Gateway. Both connections fired right up.Key Takeaway:Always create separate root certificates when creating more than one Point-to-Site Gateway.",
        "url": "/cooperlutz.github.io//2018/02/10/point-to-site-vpn.html"
      }
      
    
  };
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js"></script>
<script src="/cooperlutz.github.io/assets/js/search.js"></script></section>
</article>

    </div>
    


<footer class="site-footer">
	<p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/rohanchandra/type-theme">Type Theme</a>
</p>
</footer>


  </body>
</html>
